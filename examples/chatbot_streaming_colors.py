#!/usr/bin/env python3
"""
–°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤—ã–π —á–∞—Ç-–±–æ—Ç —Å —Ü–≤–µ—Ç–æ–≤—ã–º –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–º –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–æ–≤.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –¥–≤–∞ —Ä–µ–∂–∏–º–∞ —Ä–∞–±–æ—Ç—ã:
1. REALTIME - –æ–∫—Ä–∞—Å–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ –ø–æ –º–µ—Ä–µ –∏—Ö –ø–æ–ª—É—á–µ–Ω–∏—è
2. AGGREGATED - —Å–±–æ—Ä –≤—Å–µ—Ö —Ç–æ–∫–µ–Ω–æ–≤ –∏ –æ–∫—Ä–∞—Å–∫–∞ —Å —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π

–ó–∞–ø—É—Å–∫:
    python3 examples/chatbot_streaming_colors.py [--mode REALTIME|AGGREGATED]

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –æ–∫—Ä—É–∂–µ–Ω–∏—è:
    LLM_ENDPOINT, LLM_API_KEY (–∏–ª–∏ LLM_TOKEN), LLM_MODEL
"""

import asyncio
import argparse
import os
import sys
import time
from enum import Enum
from typing import List, Dict, Any, Optional, AsyncGenerator
from pathlib import Path

from dotenv import load_dotenv
from kraken_llm import LLMConfig, create_streaming_client, create_universal_client
from kraken_llm.utils.color import (
    colorize_text_ansi,
    colorize_tokens_ansi,
    get_confidence_legend_ansi,
    get_confidence_description,
)
from kraken_llm.streaming import token_stream_with_shadow_repair
from kraken_llm.confidence.filter import ConfidenceFilterConfig, ensure_confident_chat


class StreamingMode(Enum):
    """–†–µ–∂–∏–º—ã —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è."""
    REALTIME = "realtime"        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
    AGGREGATED = "aggregated"    # –°–±–æ—Ä –≤—Å–µ—Ö —Ç–æ–∫–µ–Ω–æ–≤ –∏ –∏—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞


class StreamingConfidenceChatBot:
    """–°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤—ã–π —á–∞—Ç-–±–æ—Ç —Å —Ü–≤–µ—Ç–æ–≤—ã–º –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏."""
    
    def __init__(self, config: LLMConfig, streaming_mode: StreamingMode = StreamingMode.REALTIME, *, min_confidence: float = 0.8, per_token_threshold: float = 0.4, max_low_conf_fraction: float = 0.34, no_rollback_marker: bool = False):
        self.config = config
        self.streaming_mode = streaming_mode
        # –ü–æ—Ä–æ–≥–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        self.min_confidence = float(min_confidence)
        self.per_token_threshold = float(per_token_threshold)
        self.max_low_conf_fraction = float(max_low_conf_fraction)
        self.no_rollback_marker = bool(no_rollback_marker)
        self.conversation_history: List[Dict[str, str]] = []
        
    async def _maybe_regenerate(self, base_messages: List[Dict[str, str]], min_confidence: float, per_token_threshold: float, max_low_conf_fraction: float) -> None:
        cfg = ConfidenceFilterConfig(
            min_confidence=min_confidence,
            max_attempts=3,
            prefer_streaming=True,
            per_token_threshold=per_token_threshold,
            max_low_conf_fraction=max_low_conf_fraction,
        )
        async with create_universal_client(self.config) as client:
            regen = await ensure_confident_chat(
                client,
                messages=base_messages,
                cfg=cfg,
                max_tokens=2048,
            )
        print("\n\nüîÅ –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (—Ñ–∏–ª—å—Ç—Ä —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏):")
        if isinstance(regen, dict):
            if regen.get("token_confidences"):
                print(colorize_tokens_ansi(regen["token_confidences"]))
            else:
                print(colorize_text_ansi(regen.get("text", ""), float(regen.get("confidence", 0.5) or 0.5)))
            print(f"\nüìà –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {regen.get('confidence', 0.0):.3f} ({regen.get('confidence_label', '')}); –ø–æ–ø—ã—Ç–æ–∫: {regen.get('attempts_made', 0)}; —É—Å–ø–µ—Ö: {regen.get('success', False)}")
        
    async def stream_response_realtime(self, user_input: str, min_confidence: float, per_token_threshold: float, max_low_conf_fraction: float) -> None:
        """
        –°—Ç—Ä–∏–º–∏—Ç –æ—Ç–≤–µ—Ç –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Å –æ–∫—Ä–∞—Å–∫–æ–π —Ç–æ–∫–µ–Ω–æ–≤.
        
        Args:
            user_input: –í–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.conversation_history.append({"role": "user", "content": user_input})
        
        print("\nü§ñ –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ (–≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏):")
        
        collected_tokens = []
        total_text = ""
        start_time = time.time()
        
        # –í—ã–±–æ—Ä —Ä–µ–∂–∏–º–∞ —Ä–µ–º–æ–Ω—Ç–∞
        repair_mode = (self.config.repair_mode or "off").lower() if hasattr(self.config, "repair_mode") else "off"
        # –†–µ–∂–∏–º —Å —Ç–µ–Ω–µ–≤—ã–º —Ä–µ–º–æ–Ω—Ç–æ–º –∏–ª–∏ —Å–µ—Ä–≤–µ—Ä–Ω—ã–π —Ä–µ–∂–∏–º: —Å—Ç—Ä–∏–º–∏–º —Ç–æ–∫–µ–Ω—ã –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
        if repair_mode in ("shadow", "server"):
            client = create_streaming_client(self.config)
            try:
                enable_cutover = (repair_mode == "shadow")
                suppress_rollback = self.no_rollback_marker and enable_cutover
                # –ë—É—Ñ–µ—Ä—ã –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Å—Ç–µ–∫ –≤–∏–¥–∏–º—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –≤ –æ–±–æ–∏—Ö —Ä–µ–∂–∏–º–∞—Ö)
                display_text_buffer = ""
                visible_tokens_stack: List[Dict[str, Any]] = []  # –¥–ª—è –∏—Ç–æ–≥–æ–≤–æ–π –æ–∫—Ä–∞—Å–∫–∏ —Ç–æ–∫–µ–Ω–æ–≤ –∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –¥–ª–∏–Ω—ã

                def _erase_last_chars(n: int) -> None:
                    # –ú—è–≥–∫–æ–µ —Å—Ç–∏—Ä–∞–Ω–∏–µ n –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –≤–∏–¥–∏–º—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
                    if n <= 0:
                        return
                    try:
                        sys.stdout.write("\b" * n + " " * n + "\b" * n)
                        sys.stdout.flush()
                    except Exception:
                        # –í –±–µ–∑–ø–µ—á–Ω–æ–º —Ä–µ–∂–∏–º–µ –ø—Ä–æ—Å—Ç–æ –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
                        pass

                async for ev in token_stream_with_shadow_repair(
                    client,
                    self.conversation_history.copy(),
                    per_token_threshold=per_token_threshold,
                    max_tokens=512,
                    enable_cutover=enable_cutover,
                ):
                    if ev.get("type") == "token":
                        token = ev.get("token", "")
                        conf = float(ev.get("confidence", 0.5) or 0.5)
                        clean_token = token.replace('ƒ†', ' ').replace('‚ñÅ', ' ')
                        if suppress_rollback:
                            # –ö–æ–ø–∏–º, –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
                            display_text_buffer += clean_token
                        else:
                            # –ü–µ—á–∞—Ç–∞–µ–º —Å –æ–∫—Ä–∞—Å–∫–æ–π
                            print(colorize_text_ansi(clean_token, conf), end="", flush=True)
                        # –í–µ–¥—ë–º —Å—Ç–µ–∫ –¥–ª—è –æ–±–æ–∏—Ö —Ä–µ–∂–∏–º–æ–≤
                        visible_tokens_stack.append({"token": token, "confidence": conf, "visible_len": len(clean_token)})
                        collected_tokens.append({"token": token, "confidence": conf})
                        total_text += clean_token
                    elif ev.get("type") == "rollback":
                        count = int(ev.get("count", 0) or 0)
                        if suppress_rollback:
                            # –£–¥–∞–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ç–æ–∫–µ–Ω –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –±—É—Ñ–µ—Ä–∞
                            if count > 0 and display_text_buffer:
                                display_text_buffer = display_text_buffer[:-count]
                            if visible_tokens_stack:
                                visible_tokens_stack.pop()
                        else:
                            # –ú—è–≥–∫–æ–µ —Å—Ç–∏—Ä–∞–Ω–∏–µ —Å —ç–∫—Ä–∞–Ω–∞ –±–µ–∑ –º–∞—Ä–∫–µ—Ä–∞
                            if count > 0:
                                _erase_last_chars(count)
                                total_text = total_text[:-count] if total_text else total_text
                            if visible_tokens_stack:
                                visible_tokens_stack.pop()
                    elif ev.get("type") == "done":
                        # –ï—Å–ª–∏ —Å–∫—Ä—ã–≤–∞–ª–∏ –æ—Ç–∫–∞—Ç—ã ‚Äî –≤—ã–≤–µ–¥–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —á–∏—Å—Ç—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–∑–æ–º
                        if suppress_rollback:
                            if visible_tokens_stack:
                                final_colored = colorize_tokens_ansi(visible_tokens_stack)
                                print(final_colored, end="", flush=True)
                                total_text = display_text_buffer  # –ø–µ—Ä–µ–∑–∞–ø–∏—à–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
                        break
            except Exception as e:
                print(f"\n‚ùå –û—à–∏–±–∫–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞: {e}")
                return
            finally:
                try:
                    await client.close()
                except Exception:
                    pass

            # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–±—Ä–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
            self.conversation_history.append({"role": "assistant", "content": total_text})
        else:
            async with create_streaming_client(self.config) as client:
                try:
                    # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–∏–º —Å confidence –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
                    response = await client.chat_completion(
                        messages=self.conversation_history.copy(),
                        include_confidence=True,
                        max_tokens=2048,
                        logprobs=True,
                        top_logprobs=5
                    )
                    
                    # –ï—Å–ª–∏ response —Å–æ–¥–µ—Ä–∂–∏—Ç token_conf–∏–¥ences, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
                    if isinstance(response, dict) and "token_confidences" in response:
                        token_confidences = response["token_confidences"]
                        text = response.get("text", "")
                        
                        print("üé® –¢–æ–∫–µ–Ω—ã —Å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏:")
                        
                        # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ç–æ–∫–µ–Ω—ã –ø–æ –º–µ—Ä–µ –∏—Ö "–ø–æ—Å—Ç—É–ø–ª–µ–Ω–∏—è" —Å –Ω–µ–±–æ–ª—å—à–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∞
                        for i, token_info in enumerate(token_confidences):
                            token = token_info.get("token", "")
                            confidence = token_info.get("confidence", 0.5)
                            
                            # –û—á–∏—â–∞–µ–º —Ç–æ–∫–µ–Ω –æ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
                            clean_token = token.replace('ƒ†', ' ').replace('‚ñÅ', ' ')
                            
                            # –û–∫—Ä–∞—à–∏–≤–∞–µ–º –∏ –≤—ã–≤–æ–¥–∏–º —Ç–æ–∫–µ–Ω
                            colored_token = colorize_text_ansi(clean_token, confidence)
                            print(colored_token, end="", flush=True)
                            
                            collected_tokens.append(token_info)
                            total_text += clean_token
                            
                            # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å—Ç—Ä–∏–º–∞
                            await asyncio.sleep(0.05)
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
                        self.conversation_history.append({"role": "assistant", "content": text})

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä–æ–≥–∏ –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –≤—ã–ø–æ–ª–Ω—è–µ–º –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏—é
                        overall_ok = float(response.get("confidence", 0.0) or 0.0) >= min_confidence
                        confidences = [float(t.get("confidence", 0.0) or 0.0) for t in token_confidences]
                        low_frac = (sum(1 for c in confidences if c < per_token_threshold) / len(confidences)) if confidences else 0.0
                        if not overall_ok or low_frac > max_low_conf_fraction:
                            base_messages = self.conversation_history[:-1]
                            await self._maybe_regenerate(base_messages, min_confidence, per_token_threshold, max_low_conf_fraction)
                        
                    else:
                        # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π —Å—Ç—Ä–∏–º –±–µ–∑ confidence
                        print("‚ö° –û–±—ã—á–Ω—ã–π —Å—Ç—Ä–∏–º (–±–µ–∑ —Ç–æ–∫–µ–Ω-—É—Ä–æ–≤–Ω–µ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫):")
                        
                        async for chunk in client.chat_completion_stream(
                            messages=self.conversation_history.copy(),
                            max_tokens=2048
                        ):
                            # –û–∫—Ä–∞—à–∏–≤–∞–µ–º chunk —Å—Ä–µ–¥–Ω–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
                            colored_chunk = colorize_text_ansi(chunk, 0.5)
                            print(colored_chunk, end="", flush=True)
                            total_text += chunk
                            await asyncio.sleep(0.02)
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–±—Ä–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
                        self.conversation_history.append({"role": "assistant", "content": total_text})
                
                except Exception as e:
                    print(f"\n‚ùå –û—à–∏–±–∫–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞: {e}")
                    return
        
        end_time = time.time()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print(f"\n\n‚è±Ô∏è  –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {end_time - start_time:.2f} —Å–µ–∫")
        if collected_tokens:
            avg_confidence = sum(t.get("confidence", 0) for t in collected_tokens) / len(collected_tokens)
            print(f"üìä –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_confidence:.3f} ({get_confidence_description(avg_confidence)})")
            print(f"üìù –í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {len(collected_tokens)}")
    
    async def stream_response_aggregated(self, user_input: str, min_confidence: float, per_token_threshold: float, max_low_conf_fraction: float) -> None:
        """
        –°–æ–±–∏—Ä–∞–µ—Ç –≤–µ—Å—å —Å—Ç—Ä–∏–º –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π.
        
        Args:
            user_input: –í–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.conversation_history.append({"role": "user", "content": user_input})
        
        print("\n‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç (—Ä–µ–∂–∏–º –∞–≥—Ä–µ–≥–∞—Ü–∏–∏)...")
        
        start_time = time.time()
        
        async with create_streaming_client(self.config) as client:
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥ —Å include_confidence –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
                response = await client.chat_completion(
                    messages=self.conversation_history.copy(),
                    include_confidence=True,
                    max_tokens=2048,
                    logprobs=True,
                    top_logprobs=5
                )
                
                if isinstance(response, dict):
                    text = response.get("text", "")
                    confidence = response.get("confidence", 0.5)
                    confidence_label = response.get("confidence_label", "—Å—Ä–µ–¥–Ω—è—è")
                    token_confidences = response.get("token_confidences", [])
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
                    self.conversation_history.append({"role": "assistant", "content": text})
                    
                    end_time = time.time()
                    
                    print("\nü§ñ –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ (–∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º):")
                    print(f"üìà –û–±—â–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.3f} ({confidence_label})")
                    
                    if token_confidences:
                        print("\nüé® –¢–µ–∫—Å—Ç —Å —Ç–æ–∫–µ–Ω-—É—Ä–æ–≤–Ω–µ–≤—ã–º –æ–∫—Ä–∞—à–∏–≤–∞–Ω–∏–µ–º:")
                        colored_text = colorize_tokens_ansi(token_confidences)
                        print(colored_text)
                        
                        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                        self._show_detailed_statistics(token_confidences, end_time - start_time)

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä–æ–≥–∏ –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –≤—ã–ø–æ–ª–Ω—è–µ–º –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏—é
                        overall_ok = float(confidence or 0.0) >= min_confidence
                        confidences = [float(t.get("confidence", 0.0) or 0.0) for t in token_confidences]
                        low_frac = (sum(1 for c in confidences if c < per_token_threshold) / len(confidences)) if confidences else 0.0
                        if not overall_ok or low_frac > max_low_conf_fraction:
                            base_messages = self.conversation_history[:-1]
                            await self._maybe_regenerate(base_messages, min_confidence, per_token_threshold, max_low_conf_fraction)
                        
                    else:
                        # Fallback - –æ–∫—Ä–∞—Å–∫–∞ –≤—Å–µ–≥–æ —Ç–µ–∫—Å—Ç–∞ –ø–æ –æ–±—â–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
                        colored_text = colorize_text_ansi(text, confidence)
                        print(f"\n{colored_text}")
                        print("‚ö†Ô∏è  –¢–æ–∫–µ–Ω-—É—Ä–æ–≤–Ω–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
                        print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {end_time - start_time:.2f} —Å–µ–∫")
                
                else:
                    # –ü—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç
                    text = str(response)
                    self.conversation_history.append({"role": "assistant", "content": text})
                    
                    end_time = time.time()
                    
                    # –û–∫—Ä–∞—à–∏–≤–∞–µ–º —Å—Ä–µ–¥–Ω–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
                    colored_text = colorize_text_ansi(text, 0.5)
                    print(f"\nü§ñ –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:\n{colored_text}")
                    print(f"‚è±Ô∏è  –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {end_time - start_time:.2f} —Å–µ–∫")
                
            except Exception as e:
                print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞: {e}")
    
    def _show_detailed_statistics(self, token_confidences: List[Dict[str, Any]], generation_time: float) -> None:
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ç–æ–∫–µ–Ω–∞–º."""
        confidences = [t.get("confidence", 0) for t in token_confidences]
        
        # –ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        avg_conf = sum(confidences) / len(confidences)
        min_conf = min(confidences)
        max_conf = max(confidences)
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–æ–≤
        very_high = sum(1 for c in confidences if c >= 0.9)
        high = sum(1 for c in confidences if 0.7 <= c < 0.9)
        medium = sum(1 for c in confidences if 0.5 <= c < 0.7)
        low = sum(1 for c in confidences if 0.3 <= c < 0.5)
        very_low = sum(1 for c in confidences if c < 0.3)
        
        print(f"\nüìä –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   ‚Ä¢ –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {generation_time:.2f} —Å–µ–∫")
        print(f"   ‚Ä¢ –í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤: {len(token_confidences)}")
        print(f"   ‚Ä¢ –°–∫–æ—Ä–æ—Å—Ç—å: {len(token_confidences) / generation_time:.1f} —Ç–æ–∫–µ–Ω–æ–≤/—Å–µ–∫")
        print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_conf:.3f} ({get_confidence_description(avg_conf)})")
        print(f"   ‚Ä¢ –î–∏–∞–ø–∞–∑–æ–Ω —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: {min_conf:.3f} - {max_conf:.3f}")
        
        print(f"\nüéØ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
        print(f"   ‚Ä¢ –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è (‚â•0.9): {very_high} —Ç–æ–∫–µ–Ω–æ–≤ ({very_high/len(confidences)*100:.1f}%)")
        print(f"   ‚Ä¢ –í—ã—Å–æ–∫–∞—è (0.7-0.9): {high} —Ç–æ–∫–µ–Ω–æ–≤ ({high/len(confidences)*100:.1f}%)")
        print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω—è—è (0.5-0.7): {medium} —Ç–æ–∫–µ–Ω–æ–≤ ({medium/len(confidences)*100:.1f}%)")
        print(f"   ‚Ä¢ –ù–∏–∑–∫–∞—è (0.3-0.5): {low} —Ç–æ–∫–µ–Ω–æ–≤ ({low/len(confidences)*100:.1f}%)")
        print(f"   ‚Ä¢ –û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è (<0.3): {very_low} —Ç–æ–∫–µ–Ω–æ–≤ ({very_low/len(confidences)*100:.1f}%)")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–∞–º—ã–µ –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
        low_conf_tokens = [t for t in token_confidences if t.get("confidence", 1) < 0.5]
        if low_conf_tokens:
            print(f"\n‚ö†Ô∏è  –¢–æ–∫–µ–Ω—ã —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é (—Ç–æ–ø 5):")
            sorted_low = sorted(low_conf_tokens, key=lambda x: x.get("confidence", 1))
            for token_info in sorted_low[:5]:
                token = token_info.get("token", "").replace('ƒ†', ' ').replace('‚ñÅ', ' ')
                conf = token_info.get("confidence", 0)
                colored_token = colorize_text_ansi(f"'{token.strip()}'", conf)
                print(f"     - {colored_token}: {conf:.3f}")
    
    def print_welcome_message(self) -> None:
        """–í—ã–≤–æ–¥–∏—Ç –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ."""
        print("=" * 70)
        print("üåä KRAKEN STREAMING CONFIDENCE CHATBOT")
        print("=" * 70)
        print(f"–†–µ–∂–∏–º —Å—Ç—Ä–∏–º–∏–Ω–≥–∞: {self.streaming_mode.value.upper()}")
        
        if self.streaming_mode == StreamingMode.REALTIME:
            print("‚Ä¢ –¢–æ–∫–µ–Ω—ã –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–º–∏ —Ü–≤–µ—Ç–∞–º–∏")
        elif self.streaming_mode == StreamingMode.AGGREGATED:
            print("‚Ä¢ –°–±–æ—Ä —Å—Ç—Ä–∏–º–∞ –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π")
        
        print("\n" + get_confidence_legend_ansi())
        print("\n–ö–æ–º–∞–Ω–¥—ã:")
        print("‚Ä¢ 'exit' –∏–ª–∏ 'quit' - –≤—ã—Ö–æ–¥")
        print("‚Ä¢ 'clear' - –æ—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞")
        print("‚Ä¢ 'mode' - —Å–º–µ–Ω–∞ —Ä–µ–∂–∏–º–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞")
        print("=" * 70)
    
    def change_mode(self) -> None:
        """–ü–æ–∑–≤–æ–ª—è–µ—Ç —Å–º–µ–Ω–∏—Ç—å —Ä–µ–∂–∏–º —Å—Ç—Ä–∏–º–∏–Ω–≥–∞."""
        print("\n–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Å—Ç—Ä–∏–º–∏–Ω–≥–∞:")
        print("1. REALTIME - –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏")
        print("2. AGGREGATED - –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
        
        while True:
            try:
                choice = input("\n–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä (1-2): ").strip()
                if choice == "1":
                    self.streaming_mode = StreamingMode.REALTIME
                    break
                elif choice == "2":
                    self.streaming_mode = StreamingMode.AGGREGATED
                    break
                else:
                    print("–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –í–≤–µ–¥–∏—Ç–µ 1 –∏–ª–∏ 2.")
            except KeyboardInterrupt:
                break
        
        print(f"\n‚úÖ –†–µ–∂–∏–º –∏–∑–º–µ–Ω–µ–Ω –Ω–∞: {self.streaming_mode.value.upper()}")
    
    def clear_history(self) -> None:
        """–û—á–∏—â–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞."""
        self.conversation_history = []
        print("‚úÖ –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω–∞.")
    
    async def process_user_input(self, user_input: str, min_confidence: float, per_token_threshold: float, max_low_conf_fraction: float) -> None:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å–æ–≥–ª–∞—Å–Ω–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–º—É —Ä–µ–∂–∏–º—É."""
        if self.streaming_mode == StreamingMode.REALTIME:
            await self.stream_response_realtime(user_input, min_confidence, per_token_threshold, max_low_conf_fraction)
        elif self.streaming_mode == StreamingMode.AGGREGATED:
            await self.stream_response_aggregated(user_input, min_confidence, per_token_threshold, max_low_conf_fraction)
    
    async def run(self) -> None:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤—ã–π —á–∞—Ç-–±–æ—Ç."""
        self.print_welcome_message()
        
        try:
            while True:
                # –ü–æ–ª—É—á–∞–µ–º –≤–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                try:
                    user_input = input("\nüë§ –í—ã: ").strip()
                except KeyboardInterrupt:
                    print("\n\nüëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                    break
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥
                if user_input.lower() in ["exit", "quit", "–≤—ã—Ö–æ–¥", "q", "–π"]:
                    print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
                    break
                elif user_input.lower() in ["clear", "–æ—á–∏—Å—Ç–∏—Ç—å"]:
                    self.clear_history()
                    continue
                elif user_input.lower() in ["mode", "—Ä–µ–∂–∏–º"]:
                    self.change_mode()
                    continue
                elif not user_input:
                    continue
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                try:
                    await self.process_user_input(
                        user_input,
                        min_confidence=self.min_confidence,
                        per_token_threshold=self.per_token_threshold,
                        max_low_conf_fraction=self.max_low_conf_fraction,
                    )
                    
                except Exception as e:
                    print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–≤–æ–¥–∞: {e}")
                    print("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
        
        except Exception as e:
            print(f"\nüí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    # –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    parser = argparse.ArgumentParser(description="–°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤—ã–π —á–∞—Ç-–±–æ—Ç —Å —Ü–≤–µ—Ç–æ–≤—ã–º –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏")
    parser.add_argument(
        "--mode",
        choices=["realtime", "aggregated"],
        default="realtime",
        help="–†–µ–∂–∏–º —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: realtime)"
    )
    parser.add_argument(
        "--min-confidence",
        type=float,
        default=0.8,
        help="–ú–∏–Ω–∏–º–∞–ª—å–Ω–æ –¥–æ–ø—É—Å—Ç–∏–º–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –∞–≤—Ç–æ–ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"
    )
    parser.add_argument(
        "--per-token-threshold",
        type=float,
        default=0.4,
        help="–ü–æ—Ä–æ–≥ –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–∞ (–¥–ª—è –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ –ø—Ä–æ—Ñ–∏–ª—é —Ç–æ–∫–µ–Ω–æ–≤)"
    )
    parser.add_argument(
        "--max-low-conf-fraction",
        type=float,
        default=0.34,
        help="–ú–∞–∫—Å. –¥–æ–ª—è —Ç–æ–∫–µ–Ω–æ–≤ –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞, –∏–Ω–∞—á–µ –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏—è"
    )
    parser.add_argument(
        "--model",
        help="–ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è)"
    )
    parser.add_argument(
        "--no-rollback-marker",
        action="store_true",
        help="–°–∫—Ä—ã–≤–∞—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –æ—Ç–∫–∞—Ç–∞ –∏ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –Ω–µ—É–¥–∞—á–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã; –≤—ã–≤–æ–¥–∏—Ç—å —Ç–æ–ª—å–∫–æ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —á–∏—Å—Ç—ã–π –æ—Ç–≤–µ—Ç"
    )
    parser.add_argument(
        "--endpoint",
        help="Endpoint API (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –æ–∫—Ä—É–∂–µ–Ω–∏—è)"
    )
    parser.add_argument(
        "--repair-mode",
        choices=["off", "shadow", "server"],
        default=os.getenv("LLM_REPAIR_MODE", "off"),
        help="–†–µ–∂–∏–º —Ä–µ–º–æ–Ω—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤: off | shadow (—Ç–µ–Ω–µ–≤–æ–π —Ñ–æ—Ä–∫) | server (—Å–µ—Ä–≤–µ—Ä–Ω—ã–π –ø–æ—Ä–æ–≥ min_p)"
    )
    parser.add_argument(
        "--server-min-p",
        type=float,
        default=None,
        help="–ü–æ—Ä–æ–≥ min_p –¥–ª—è —Å–µ—Ä–≤–µ—Ä–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ (–µ—Å–ª–∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –±—ç–∫–µ–Ω–¥–æ–º, –Ω–∞–ø—Ä–∏–º–µ—Ä vLLM)"
    )
    parser.add_argument(
        "--max-attempts-per-token",
        type=int,
        default=int(os.getenv("LLM_MAX_ATTEMPTS_PER_TOKEN", "3")),
        help="–ú–∞–∫—Å–∏–º—É–º –ø–æ–ø—ã—Ç–æ–∫ –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –ö–ê–ñ–î–û–ì–û –Ω–∏–∑–∫–æ—É–≤–µ—Ä–µ–Ω–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞"
    )
    
    args = parser.parse_args()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    load_dotenv()
    
    config = LLMConfig(
        endpoint=args.endpoint or os.getenv("LLM_ENDPOINT"),
        api_key=os.getenv("LLM_API_KEY") or os.getenv("LLM_TOKEN"),
        model=args.model or os.getenv("LLM_MODEL"),
        temperature=0.7,
        stream=True,  # –í–∫–ª—é—á–∞–µ–º —Å—Ç—Ä–∏–º–∏–Ω–≥ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è logprobs –≤ —Å—Ç—Ä–∏–º–µ
        logprobs=True,
        top_logprobs=5,
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ —Å—Ç—Ä–∏–º–∞
        force_openai_streaming=True,
        suppress_stream_warnings=True,
        # Live-—Ä–µ–º–æ–Ω—Ç
        repair_mode=args.repair_mode,
        per_token_repair_threshold=args.per_token_threshold,
        server_min_p=args.server_min_p,
        max_attempts_per_token=args.max_attempts_per_token,
    )
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    if not config.api_key:
        print("‚ùå –û—à–∏–±–∫–∞: –Ω–µ –∑–∞–¥–∞–Ω API –∫–ª—é—á. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ LLM_API_KEY –∏–ª–∏ LLM_TOKEN")
        return
    
    # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤—ã–π —á–∞—Ç-–±–æ—Ç
    streaming_mode = StreamingMode(args.mode)
    chatbot = StreamingConfidenceChatBot(
        config,
        streaming_mode,
        min_confidence=args.min_confidence,
        per_token_threshold=args.per_token_threshold,
        max_low_conf_fraction=args.max_low_conf_fraction,
        no_rollback_marker=bool(args.no_rollback_marker),
    )
    
    await chatbot.run()


if __name__ == "__main__":
    asyncio.run(main())